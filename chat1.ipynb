{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# load and set our key\n",
    "openai.api_key = open(\"key.txt\", \"r\").read().strip(\"\\n\")\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User's input was:  what are the best practices when I'm getting started with kaggle competitions?\n",
      "When getting started with Kaggle competitions, there are several best practices to follow:\n",
      "\n",
      "1. Read and understand the competition rules: Familiarize yourself with the competition guidelines, evaluation criteria, and any specific rules or constraints mentioned. This helps you understand what is expected and what you are aiming for.\n",
      "\n",
      "2. Explore and understand the data: Spend time analyzing and understanding the provided data. This involves examining the structure, features, and relationships within the data. Explore any potential anomalies, missing values, or outliers that may need preprocessing or cleaning.\n",
      "\n",
      "3. Set up an evaluation metric: Make sure you understand the evaluation metric specified for the competition. This helps you frame your problem statement and guides you to choose appropriate models and techniques.\n",
      "\n",
      "4. Participate in the competition forum: Engage with fellow competitors in the competition's forum. This is a great place to get clarifications, discuss strategies, learn from others, and share your ideas. Collaboration can be immensely valuable in finding optimal solutions.\n",
      "\n",
      "5. Start with simple models: Initially, focus on building simple and interpretable models to establish a baseline performance. This helps in getting a sense of the data and its behavior, while also identifying any potential issues or challenges.\n",
      "\n",
      "6. Feature engineering: Feature engineering plays a crucial role in improving model performance. Spend time creating new features from the existing data that may capture latent information, relationships, or patterns. Feature selection and dimensionality reduction techniques can help in optimizing the model's performance and reducing computational complexity.\n",
      "\n",
      "7. Model selection and hyperparameter tuning: Explore different machine learning models suitable for the problem at hand. Experiment with various algorithms, ensemble methods, or deep learning architectures to find the right model. Additionally, perform hyperparameter tuning for each model to optimize their performance.\n",
      "\n",
      "8. Cross-validation and ensembling: Use cross-validation techniques to estimate the performance of your models and prevent overfitting. By averaging or combining predictions from multiple models through techniques like stacking, blending, or bagging, you can potentially improve performance.\n",
      "\n",
      "9. Regularly submit and track progress: Make frequent submissions to the competition platform to obtain feedback on the performance of your models. This allows you to track your progress and identify potential areas for improvement.\n",
      "\n",
      "10. Learn from other solutions: Once the competition is over, analyze and learn from the top-performing solutions. Understand the techniques, models, and approaches used by the winners and other successful participants. This helps you improve your skills and learn new methodologies.\n",
      "\n",
      "Remember that Kaggle competitions are not just about winning but also about learning and refining your skills. Embrace the opportunity to learn from others, experiment with new techniques, and continually iterate upon your models and approaches.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "message_history = []\n",
    "title = \"kaggle_best_practices\"\n",
    "time = datetime.now().strftime(\"%Y-%m-%d_%H:%M:%S\")\n",
    "model = \"gpt-3.5-turbo\"\n",
    "# model = \"gpt-4\"\n",
    "\n",
    "def chat(inp, model=model, role=\"user\"):\n",
    "    message_history.append({\"role\": role, \"content\": f\"{inp}\"})\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=message_history\n",
    "    )\n",
    "    reply_content = completion.choices[0].message.content\n",
    "    message_history.append({\"role\": \"assistant\", \"content\": f\"{reply_content}\"})\n",
    "    return reply_content\n",
    "\n",
    "def save_chat(history, title, time):\n",
    "    with open(f\"chat/{title}_{time}.txt\", \"w\") as f:\n",
    "        f.write(f\"model: {model}\\n\")\n",
    "        for message in history:\n",
    "            f.write(f\"{message['role']}: {message['content']}\\n\")\n",
    "            \n",
    "\n",
    "while True:\n",
    "    user_input = input(\"> \")\n",
    "    if user_input == \"quit\":\n",
    "        save_chat(message_history, title, time)\n",
    "        break\n",
    "    print(\"User's input was: \", user_input)\n",
    "    print(chat(user_input))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
